{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finite-arnold",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">This notebook was used to automate the process of hyperparameters tuning </span>\n",
    "We grouped the whole process from setting the parameters until training the model into one function that we iterate over in order to vary the hyperparameter we wish to optimize, the metrics are then saved inside of a textfile after each model is done training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-steal",
   "metadata": {},
   "source": [
    "# Deezer playlist dataset and song recommendation with word2vec\n",
    "\n",
    "In this mini project we will develop a word2vec network and use it to build a playlist completion tool (song suggestion). The data is hosted on the following repository: http://github.com/comeetie/deezerplay.git. To know more about word2vec and these data you can read the two following references:\n",
    "\n",
    "- Efficient estimation of word representations in vector space, Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. (https://arxiv.org/abs/1301.3781)\n",
    "- Word2with applied to Recommendation: Hyperparameters Matter, H. Caselles-Dupré, F. Lesaint and J. Royo-Letelier. (https://arxiv.org/pdf/1804.04212.pdf)\n",
    "\n",
    "The elements you have to do are highlighted in red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-activation",
   "metadata": {},
   "source": [
    "## Preparation of data\n",
    "\n",
    "The data is in the form of a playlist list. Each playlist is a list with the deezer ID of the psong followed by the artist ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breeding-chance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100000, 24.21338]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"./music_2.npy\",allow_pickle=True)\n",
    "[len(data), np.mean([len(p) for p in data])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-street",
   "metadata": {},
   "source": [
    "The dataset we are going to work on contains 100000 playlists which are composed of an average of 24.1 songs. We will start by keeping only the song identifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungry-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_track = [list(filter(lambda w: w.split(\"_\")[0]==u\"track\",playlist)) for playlist in data]\n",
    "playlist_artist = [list(filter(lambda w: w.split(\"_\")[0]==u\"artist\",playlist)) for playlist in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southwest-major",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338509"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# songs != ?\n",
    "tracks = np.unique(np.concatenate(playlist_track))\n",
    "Vt = len(tracks)\n",
    "Vt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-sheriff",
   "metadata": {},
   "source": [
    "The number of different songs in this data-set is quite high with more than 300,000 songs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-jenny",
   "metadata": {},
   "source": [
    "## Creating a song dictionary\n",
    "We will assign to each song an integer that will serve as a unique identifier and input for our network. In order to save a little bit of resources we will only work in this project on songs that appear in at least two playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "contrary-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many occurence for each track ?\n",
    "track_counts = dict((tracks[i],0) for i in range(0, Vt))\n",
    "for p in playlist_track:\n",
    "    for a in p:\n",
    "        track_counts[a]=track_counts[a]+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "corrected-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter very rare songs to save ressources\n",
    "playlist_track_filter = [list(filter(lambda a : track_counts[a]> 1, playlist)) for playlist in playlist_track]\n",
    "# get the counts\n",
    "counts  =  np.array(list(track_counts.values()))\n",
    "# sort\n",
    "order = np.argsort(-counts)\n",
    "# deezed_id array\n",
    "tracks_list_ordered = np.array(list(track_counts.keys()))[order]\n",
    "# Vocabulary size = number of kept songs\n",
    "Vt=np.where(counts[order]==1)[0][0]\n",
    "# dict construction id_morceaux num_id [0,Vt]\n",
    "track_dict = dict((tracks_list_ordered[i],i) for i in range(0, Vt))\n",
    "# playlist conversion to list of integers\n",
    "corpus_num_track = [[track_dict[track] for track in play ] for play in playlist_track_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-publicity",
   "metadata": {},
   "source": [
    "### Creation of test and validation learning sets\n",
    "\n",
    "To learn the parameters of our method we will keep the first l-1 songs of each playlist (with l the length of the playlist) for learning. To evaluate the completion performance of our method we keep for each playlist the last two songs. The objective will be to find the last one from the next-to-last one. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "disturbed-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist main part used for trainning\n",
    "play_app  = [corpus_num_track[i][:(len(corpus_num_track[i])-1)] \n",
    "             for i in range(len(corpus_num_track)) if len(corpus_num_track[i])>1]\n",
    "# the two last elements are used for validation and training\n",
    "index_tst = np.random.choice(100000,20000)\n",
    "index_val = np.setdiff1d(range(100000),index_tst)\n",
    "\n",
    "play_tst  = np.array([corpus_num_track[i][(len(corpus_num_track[i])-2):len(corpus_num_track[i])] \n",
    "             for i in index_tst if len(corpus_num_track[i])>3])\n",
    "play_val  = np.array([corpus_num_track[i][(len(corpus_num_track[i])-2):len(corpus_num_track[i])] \n",
    "             for i in index_val if len(corpus_num_track[i])>3])[:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "uniform-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense,Flatten\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-richardson",
   "metadata": {},
   "source": [
    "### hyper-paramètres de word2vec :\n",
    "\n",
    "La méthode word2vec fait intervennir un certains nombre d'hyper paramètres. Nous allons les définirs et leurs donner des première valeurs que nous affinerons par la suite:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecological-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "remarkable-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_process(vector_dim_input,window_width_input,neg_sample_input,min_batch_size_input,samp_coef_input,sub_samp_input):  \n",
    "    # latent space dimension\n",
    "    vector_dim = vector_dim_input\n",
    "    # window size\n",
    "    window_width = window_width_input\n",
    "    # number of negative sample per positive sample\n",
    "    neg_sample = neg_sample_input\n",
    "    # taille des mini-batch\n",
    "    min_batch_size = min_batch_size_input\n",
    "    # smoothing factor for the sampling table of negative pairs \n",
    "    samp_coef = samp_coef_input\n",
    "    # cparameter to sub-sample frequent song\n",
    "    sub_samp = sub_samp_input\n",
    "\n",
    "    # get the counts\n",
    "    counts = np.array(list(track_counts.values()),dtype='float')[order[:Vt]]\n",
    "    # normalization\n",
    "    st =  counts/np.sum(counts)\n",
    "    # smoothing\n",
    "    st_smooth = np.power(st,samp_coef)\n",
    "    st_smooth = st_smooth/np.sum(st_smooth)\n",
    "\n",
    "    # inputs\n",
    "    input_target = Input((1,), dtype='int32')\n",
    "    input_context = Input((1,), dtype='int32')\n",
    "\n",
    "    embedding = Embedding(Vt, vector_dim, input_length=1, name='embedding')\n",
    "    target = embedding(input_target)\n",
    "    context = embedding(input_context)\n",
    "    dot_product = Dot(axes=2, normalize=True)([target, context])\n",
    "    dot_product = Flatten()(dot_product)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid',name=\"classif\")(dot_product)\n",
    "\n",
    "    Track2Vec = Model(inputs=[input_target, input_context], outputs=output)\n",
    "    Track2Vec.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "\n",
    "    # function to generate word2vec positive and begative pairs \n",
    "    # from an array of int that represent a text ot here a playlist\n",
    "    # params \n",
    "    # seq : input text or playlist (array of int)\n",
    "    # neg_samples : number of negative sample to generate per positive ones\n",
    "    # neg_sampling_table : sampling table for negative samples\n",
    "    # sub sampling_table : sampling table for sub sampling common words songs\n",
    "    # sub_t : sub sampling parameter\n",
    "    def word2vecSampling(seq,window,neg_samples,neg_sampling_table,sub_sampling_table,sub_t):\n",
    "        # vocab size\n",
    "        V = len(neg_sampling_table)\n",
    "        # extract positive pairs \n",
    "        positives = skipgrams(sequence=seq, vocabulary_size=V, window_size=window,negative_samples=0)\n",
    "        ppairs    = np.array(positives[0])\n",
    "        # sub sampling\n",
    "        if (ppairs.shape[0]>0):\n",
    "            f = sub_sampling_table[ppairs[:,0]]\n",
    "            subprob = ((f-sub_t)/f)-np.sqrt(sub_t/f)\n",
    "            tokeep = (subprob<np.random.uniform(size=subprob.shape[0])) | (subprob<0)\n",
    "            ppairs = ppairs[tokeep,:]\n",
    "        nbneg     = ppairs.shape[0]*neg_samples\n",
    "        # sample negative pairs\n",
    "        if (nbneg > 0):\n",
    "            negex     = np.random.choice(V, nbneg, p=neg_sampling_table)\n",
    "            negexcontext = np.repeat(ppairs[:,0],neg_samples)\n",
    "            npairs    = np.transpose(np.stack([negexcontext,negex]))\n",
    "            pairs     = np.concatenate([ppairs,npairs],axis=0)\n",
    "            labels    = np.concatenate([np.repeat(1,ppairs.shape[0]),np.repeat(0,nbneg)])\n",
    "            perm      = np.random.permutation(len(labels))\n",
    "            res = [pairs[perm,:],labels[perm]]\n",
    "        else:\n",
    "            res=[[],[]]\n",
    "        return res\n",
    "\n",
    "    import random\n",
    "\n",
    "    def track_ns_generator(corpus_num, nbm):\n",
    "\n",
    "        while 1:\n",
    "\n",
    "            # tirage de nbm playlist dans corpus_num\n",
    "            result = [word2vecSampling(batch, window_width, neg_sample, st_smooth, st, sub_samp) for batch in random.sample(corpus_num, nbm)]\n",
    "            x_temp = np.array([i for fxres in [rot[0] for rot in result if len(rot[0]) > 0] for i in fxres], dtype=np.int32)\n",
    "\n",
    "            # création des données x et y \n",
    "            y = np.array([i for fyres in [rot[1] for rot in result if len(rot[1]) > 0] for i in fyres], dtype=np.int32)\n",
    "            x = [x_temp[:,0], x_temp[:,1]]\n",
    "\n",
    "            yield (x, y)\n",
    "\n",
    "    start_time = time.time()\n",
    "    #Learning\n",
    "    # %%script false --no-raise-error\n",
    "    hist=Track2Vec.fit(x=track_ns_generator(play_app,min_batch_size),steps_per_epoch = 200,epochs=60)\n",
    "    end_time = time.time()\n",
    "    #save weights\n",
    "    vectors_tracks = Track2Vec.get_weights()[0]\n",
    "    with open('latent_positions.npy', 'wb') as f:\n",
    "        np.save(f, vectors_tracks)\n",
    "    #load them    \n",
    "    vectors_tracks=np.load(\"latent_positions.npy\")\n",
    "    #closest neighbours algo (+- 5min on top of the training time)\n",
    "    kdt = KDTree(vectors_tracks, leaf_size=10, metric='euclidean')\n",
    "    def predict_batch(seeds,k,X,kdt):\n",
    "        return kdt.query(X[seeds,:], k=k+1, return_distance=False)[:,1:]\n",
    "    indexes = predict_batch(play_val[:,0],10,vectors_tracks,kdt)\n",
    "\n",
    "    #metrics that we have to keep track of along with accuracy\n",
    "    \n",
    "    NDGCatK=0\n",
    "    for k in [np.where(indexes[i] == value)[0] for i, value in enumerate(play_val[:,1])]:\n",
    "        if len(k)>0:\n",
    "            NDGCatK+= sum(1/np.log2(k+2))/len(play_val[:,1])\n",
    "    \n",
    "    n,HitatK = 0,0\n",
    "    for i,value in enumerate(play_val[:,1]):\n",
    "        if value in indexes[i]:\n",
    "            n+=1\n",
    "    HitatK = n/len(play_val[:,1])\n",
    "    \n",
    "    #save hyperparameters used + metrics + computational time in a file\n",
    "    f = open(\"Results.txt\", \"a\")\n",
    "    f.write(\"samp_coef= {} || NDGCatK={} || HitatK={} || accuracy={} || loss={} || computational time={} seconds  \\n\"\n",
    "            .format(samp_coef_input,NDGCatK,HitatK,hist.history.get('accuracy')[-1],hist.history.get('loss')[-1],end_time - start_time))\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "manual-preference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.6631 - accuracy: 0.6345\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.6064 - accuracy: 0.8095\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.5571 - accuracy: 0.8473\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.5073 - accuracy: 0.8608\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4553 - accuracy: 0.8784\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4136 - accuracy: 0.8873\n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3882 - accuracy: 0.8899\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3666 - accuracy: 0.89470s - loss: 0.3664 - ac\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3478 - accuracy: 0.90071s - los\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3321 - accuracy: 0.9048\n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3207 - accuracy: 0.9078\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3053 - accuracy: 0.91180s - loss: 0.3055 - accuracy: 0.\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2972 - accuracy: 0.9132\n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2852 - accuracy: 0.9158\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2787 - accuracy: 0.9191\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2699 - accuracy: 0.9209\n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.2599 - accuracy: 0.9237\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.2543 - accuracy: 0.9255\n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2482 - accuracy: 0.9271\n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.2392 - accuracy: 0.9299\n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2328 - accuracy: 0.9317\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2244 - accuracy: 0.9348\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.2201 - accuracy: 0.93593s - l\n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2113 - accuracy: 0.9387\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.2060 - accuracy: 0.9395\n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2015 - accuracy: 0.9410\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1934 - accuracy: 0.9441\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1884 - accuracy: 0.9452s - loss: 0.1883 - \n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1876 - accuracy: 0.9451\n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1816 - accuracy: 0.94661s - los\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.1785 - accuracy: 0.9473\n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.1756 - accuracy: 0.9487\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1725 - accuracy: 0.9489\n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1639 - accuracy: 0.9514\n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1631 - accuracy: 0.95154s - loss: 0.1631 -  - E\n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.1610 - accuracy: 0.95150s - loss: 0.1612 - accuracy: 0.\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1573 - accuracy: 0.9532: 15s - loss: 0.1646 - accuracy: - ETA: 15s - loss: 0.1661 - accur - ETA: 15s - loss: - ETA: 1s - loss:\n",
      "Epoch 38/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1517 - accuracy: 0.95490s - loss: 0.1516 - accuracy: \n",
      "Epoch 39/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1501 - accuracy: 0.95463s - loss: 0.1 - ETA: 1s - loss: 0.1498 - ac - ETA: 1s - loss: 0.1496 - accu - ETA: 0s - loss: 0.1499 - accuracy: 0. - ETA: 0s - loss: 0.1499 - accuracy - ETA: 0s - loss: 0.1502 - accuracy: 0.\n",
      "Epoch 40/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1459 - accuracy: 0.9561ETA: 3s - loss: 0.1466 - accuracy: 0.95 - ETA: 3s - l\n",
      "Epoch 41/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.1419 - accuracy: 0.9567\n",
      "Epoch 42/60\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.1406 - accuracy: 0.9574\n",
      "Epoch 43/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1383 - accuracy: 0.9577\n",
      "Epoch 44/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1347 - accuracy: 0.95912s - loss: 0.1351 - ac\n",
      "Epoch 45/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1317 - accuracy: 0.9597\n",
      "Epoch 46/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1293 - accuracy: 0.9603\n",
      "Epoch 47/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.1282 - accuracy: 0.9604\n",
      "Epoch 48/60\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.1288 - accuracy: 0.9600\n",
      "Epoch 49/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1256 - accuracy: 0.9610\n",
      "Epoch 50/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.1231 - accuracy: 0.9616: 14s - loss: 0.1276 - accuracy: 0.9 - ETA: 14s - loss:  - ETA: 9s - loss: 0.1225 - accuracy: 0. - ETA: 9s - loss: - E\n",
      "Epoch 51/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.1199 - accuracy: 0.9627\n",
      "Epoch 52/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.1216 - accuracy: 0.9618s - loss: 0.1216 - accuracy: \n",
      "Epoch 53/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1178 - accuracy: 0.96320s - loss: 0.1176 - \n",
      "Epoch 54/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.1168 - accuracy: 0.96312s - - ETA: 0s - loss: 0.1168 - accu\n",
      "Epoch 55/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1150 - accuracy: 0.9636s - loss: 0.1152 - accuracy: \n",
      "Epoch 56/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1146 - accuracy: 0.9638\n",
      "Epoch 57/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1113 - accuracy: 0.96471s\n",
      "Epoch 58/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1131 - accuracy: 0.9639\n",
      "Epoch 59/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1109 - accuracy: 0.9647: 1 - ETA: 10s - loss: 0.1105 - accuracy: 0. - ETA: 10s \n",
      "Epoch 60/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1078 - accuracy: 0.9660\n",
      "Epoch 1/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.6651 - accuracy: 0.6931\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.6099 - accuracy: 0.8323\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.5677 - accuracy: 0.8333\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.5343 - accuracy: 0.8333\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.5072 - accuracy: 0.8333s - loss: 0.507\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4756 - accuracy: 0.8333\n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4397 - accuracy: 0.8333\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4249 - accuracy: 0.8333\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4204 - accuracy: 0.8333\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.4186 - accuracy: 0.8334\n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4156 - accuracy: 0.8334\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4135 - accuracy: 0.83363s - loss: 0 - ETA - ETA: 0s - loss: 0.4133 - accuracy:  - ETA: 0s - loss: 0.4133 - accu\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4112 - accuracy: 0.8337\n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4104 - accuracy: 0.8341\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4075 - accuracy: 0.8345\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4068 - accuracy: 0.8348\n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4052 - accuracy: 0.8352\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4035 - accuracy: 0.8359\n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4026 - accuracy: 0.8366\n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3999 - accuracy: 0.8376\n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4005 - accuracy: 0.8380\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3986 - accuracy: 0.8392\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3951 - accuracy: 0.8402\n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3932 - accuracy: 0.8413\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3935 - accuracy: 0.8425s - loss: 0.3929 \n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3912 - accuracy: 0.8434\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3900 - accuracy: 0.8450 15s - loss: 0.3902 - accuracy: 0 - ETA: 15s - ETA: 6s - loss: 0.390 - ETA:  - ETA: 3s - loss: 0.3899 - accuracy:  - E - ETA: 1s - loss: 0\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3884 - accuracy: 0.8455\n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3880 - accuracy: 0.8465\n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3860 - accuracy: 0.8481\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3856 - accuracy: 0.8485\n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3859 - accuracy: 0.8502\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3841 - accuracy: 0.8503: 14s - loss: 0.3880 \n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3832 - accuracy: 0.8515: 16s - loss: 0.3854 - accuracy: 0.851 - ETA: 16s - loss: 0.3850 -   - ETA:  - ETA: 0s - loss: 0.3832 - accuracy: 0.\n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3823 - accuracy: 0.85264s - loss: 0.3833 -  - ETA: 3s - loss: 0.3834 - accura - ETA: 2s - loss: 0.3833 \n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3824 - accuracy: 0.8533\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3825 - accuracy: 0.8536\n",
      "Epoch 38/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3818 - accuracy: 0.85471s - loss: 0.3819 -  - ETA: 1s - loss: 0\n",
      "Epoch 39/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3779 - accuracy: 0.8554: 17s - loss: 0.3728 - acc - ETA: 17 - ETA: 5s - loss: 0.3772 - accu - ETA: 4s - loss: 0.3769 - ac\n",
      "Epoch 40/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3795 - accuracy: 0.8561\n",
      "Epoch 41/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3777 - accuracy: 0.8572\n",
      "Epoch 42/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3758 - accuracy: 0.8586s - loss: 0.3757 - ac\n",
      "Epoch 43/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3755 - accuracy: 0.85950s - loss: 0.375\n",
      "Epoch 44/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3735 - accuracy: 0.8606\n",
      "Epoch 45/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3735 - accuracy: 0.86157s - loss: 0.3739 \n",
      "Epoch 46/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3725 - accuracy: 0.8618\n",
      "Epoch 47/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3715 - accuracy: 0.86262s - loss: 0.3699 -  - E\n",
      "Epoch 48/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3714 - accuracy: 0.8629\n",
      "Epoch 49/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3700 - accuracy: 0.8632\n",
      "Epoch 50/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3666 - accuracy: 0.8644\n",
      "Epoch 51/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3700 - accuracy: 0.86350s - loss: 0.3701 - accuracy: 0.\n",
      "Epoch 52/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3673 - accuracy: 0.86501s - loss: 0.367 - ETA: 0s - loss: 0.3678 \n",
      "Epoch 53/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3696 - accuracy: 0.86491s - loss: - ETA: 0s - loss: 0.3698 - accuracy\n",
      "Epoch 54/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3708 - accuracy: 0.8647: 14s - loss: 0.3709 -  - ETA: 13s -  - ETA: 11s - loss: 0.3706 - a - ETA: 9s - loss: 0.3695 - accuracy:  - ETA: 9s - los - ETA: 8s - loss: 0.3696 -  - ETA: 0s - loss: 0.371\n",
      "Epoch 55/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3686 - accuracy: 0.8655\n",
      "Epoch 56/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3718 - accuracy: 0.86550s - loss: 0.3715 - accuracy\n",
      "Epoch 57/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3674 - accuracy: 0.8655\n",
      "Epoch 58/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3685 - accuracy: 0.8665\n",
      "Epoch 59/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3701 - accuracy: 0.8663\n",
      "Epoch 60/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3675 - accuracy: 0.86661s - loss: 0.366 - ETA: 0s - loss: 0.367\n",
      "Epoch 1/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.6647 - accuracy: 0.7038\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.6101 - accuracy: 0.8329\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.5672 - accuracy: 0.8333\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.5345 - accuracy: 0.8333\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.5068 - accuracy: 0.8333\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4722 - accuracy: 0.8333\n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4374 - accuracy: 0.83332s - los - ETA: 1s - loss: 0.4381 - accuracy:  - ETA: 1s - loss: 0.4380 - ac - ETA: 0s - loss: 0.4376 - ac\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4254 - accuracy: 0.8334\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4224 - accuracy: 0.8333\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4203 - accuracy: 0.8334\n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4173 - accuracy: 0.8334\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4163 - accuracy: 0.8335TA: 0s - loss: 0.4160 - ac\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4144 - accuracy: 0.83366s - loss: 0.4150 - ac - ETA: 6s - loss: 0.414 - ETA: 5s - loss: 0.4147  - ETA: 4s - loss: 0.4147 - accuracy - ETA - ETA: 2s - loss: 0.4147 - accuracy: 0.83 - ETA: 1s - loss: 0.414 - ETA: 0s - loss: 0.4\n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4149 - accuracy: 0.8338s - loss: 0.4149 - accu\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.4121 - accuracy: 0.8341\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4085 - accuracy: 0.83445s - loss: 0\n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4092 - accuracy: 0.8349\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4072 - accuracy: 0.8354\n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4053 - accuracy: 0.8359\n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4048 - accuracy: 0.8364\n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4017 - accuracy: 0.8371\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4013 - accuracy: 0.8381\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4001 - accuracy: 0.8389: 0s - loss: 0.3997 \n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3976 - accuracy: 0.84003s - ETA: 1s - loss: 0.3977 -  - ETA: 1s - loss: 0.3978 -  - ETA: 0s - loss: 0.3979 - accura\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3984 - accuracy: 0.8408\n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3960 - accuracy: 0.8414\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3926 - accuracy: 0.8427s - loss: 0 - ETA: 0s - loss: 0.3926 - accuracy: 0.84\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.3937 - accuracy: 0.8434\n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3915 - accuracy: 0.8451\n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3920 - accuracy: 0.8450ETA: 1s - loss: 0.3921 - accuracy: 0.84 - ETA: 1s - los\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3913 - accuracy: 0.84620s - loss: 0.3913 - \n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3900 - accuracy: 0.8469\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3916 - accuracy: 0.8474\n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3883 - accuracy: 0.84795s - l\n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3876 - accuracy: 0.84900s - loss: 0.3878 \n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3888 - accuracy: 0.8498\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3869 - accuracy: 0.85090s - loss: 0.3867 - accuracy: \n",
      "Epoch 38/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3839 - accuracy: 0.8515: 15s - loss: 0.3847 - accuracy:  - E - ETA: \n",
      "Epoch 39/60\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3847 - accuracy: 0.8524\n",
      "Epoch 40/60\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3830 - accuracy: 0.8533\n",
      "Epoch 41/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3824 - accuracy: 0.85381s - loss:\n",
      "Epoch 42/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3827 - accuracy: 0.8546: 16 - ETA: 3s - loss: 0.3812  - ETA: 2s - loss: 0.3821 -  - ETA: 1s -\n",
      "Epoch 43/60\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3793 - accuracy: 0.8554 - ETA: 0s - loss: 0.3796 - \n",
      "Epoch 44/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3784 - accuracy: 0.8564\n",
      "Epoch 45/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3785 - accuracy: 0.85742s - loss: 0.3779 - accuracy\n",
      "Epoch 46/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3772 - accuracy: 0.8576\n",
      "Epoch 47/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3791 - accuracy: 0.8583\n",
      "Epoch 48/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3761 - accuracy: 0.8585\n",
      "Epoch 49/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3764 - accuracy: 0.85856s - loss: 0.3778 -  - ETA: 5s\n",
      "Epoch 50/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3772 - accuracy: 0.85911s\n",
      "Epoch 51/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3789 - accuracy: 0.8595: 17s - loss: 0.\n",
      "Epoch 52/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3772 - accuracy: 0.8596\n",
      "Epoch 53/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3745 - accuracy: 0.8599\n",
      "Epoch 54/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3757 - accuracy: 0.8599\n",
      "Epoch 55/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3772 - accuracy: 0.8598\n",
      "Epoch 56/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3730 - accuracy: 0.8608\n",
      "Epoch 57/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3762 - accuracy: 0.8609\n",
      "Epoch 58/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3729 - accuracy: 0.86117s - loss: 0.3733 - accura - ETA: 6s - loss: 0.3729 - accu - ETA\n",
      "Epoch 59/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3740 - accuracy: 0.8618\n",
      "Epoch 60/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3724 - accuracy: 0.8621\n",
      "Epoch 1/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.6780 - accuracy: 0.5887\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.6194 - accuracy: 0.7462\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.5711 - accuracy: 0.8210\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.5331 - accuracy: 0.8332\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4979 - accuracy: 0.8334\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4645 - accuracy: 0.8334s - loss: 0.4656 - ac - ETA: 0s - loss: 0.4650 \n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.4379 - accuracy: 0.8333\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4265 - accuracy: 0.8334s\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4234 - accuracy: 0.8335\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4219 - accuracy: 0.8336 1 - ETA: 14s - loss: 0. - ETA: 12s - loss: 0.4205 - ac - ETA: 11s - loss: 0.4208 - ETA: 3s - loss: 0.4\n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4211 - accuracy: 0.83377s - loss: 0.421 - ETA: 6s - loss: 0.4209 - accuracy:  - ETA: 5s\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4177 - accuracy: 0.8338 12s - loss: 0.4 - ET - ETA\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4180 - accuracy: 0.8340\n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4163 - accuracy: 0.8343\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4140 - accuracy: 0.8344\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4123 - accuracy: 0.8348\n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4113 - accuracy: 0.8352\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4105 - accuracy: 0.83550s - loss: 0.4105 - accuracy: \n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4093 - accuracy: 0.83643s - loss: 0.4097 - accura - ETA:  - ETA: 1s -\n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4080 - accuracy: 0.83641s - loss:\n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4059 - accuracy: 0.8371\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4059 - accuracy: 0.8379\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4055 - accuracy: 0.83835s - l - ETA: 4s - loss: 0.4057 - accuracy: 0. - ETA: 4s - los - ETA: 2s - loss: 0.4055 \n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4053 - accuracy: 0.8388\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4028 - accuracy: 0.8393\n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4026 - accuracy: 0.83991s -\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4006 - accuracy: 0.8405\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4017 - accuracy: 0.8411\n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4020 - accuracy: 0.8415\n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4001 - accuracy: 0.8421s - loss: 0.3999 - ac - ETA: 0s - loss: 0.4001 - accuracy: 0.84\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3978 - accuracy: 0.8424TA - ETA: 1s - loss: 0.3976 - accuracy - ETA: 0s - loss: 0.3976 \n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3994 - accuracy: 0.8432\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3973 - accuracy: 0.8434\n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.3973 - accuracy: 0.8442s - loss: 0.3973 - accuracy: 0.\n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3962 - accuracy: 0.8444 ETA - ETA: 0s - loss: 0.3959  - ETA: 0s - loss: 0.3963 - accuracy: 0.\n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3947 - accuracy: 0.8456\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3957 - accuracy: 0.8456 1\n",
      "Epoch 38/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3938 - accuracy: 0.8465\n",
      "Epoch 39/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3931 - accuracy: 0.8472\n",
      "Epoch 40/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3917 - accuracy: 0.8475s - los - ETA: \n",
      "Epoch 41/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3904 - accuracy: 0.84811s - l\n",
      "Epoch 42/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3892 - accuracy: 0.8485\n",
      "Epoch 43/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3899 - accuracy: 0.8488\n",
      "Epoch 44/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3869 - accuracy: 0.85005s - ETA: \n",
      "Epoch 45/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3884 - accuracy: 0.8504 - ETA: 9s - loss: 0.3900 - accurac - ETA: 9s - loss: 0.3895 - accuracy:  - ETA: 9s - loss: 0.3 - - ETA\n",
      "Epoch 46/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3890 - accuracy: 0.8509\n",
      "Epoch 47/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3880 - accuracy: 0.8507\n",
      "Epoch 48/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3890 - accuracy: 0.8513\n",
      "Epoch 49/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3859 - accuracy: 0.8515\n",
      "Epoch 50/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3896 - accuracy: 0.8514s - loss: 0.3892 - accuracy: \n",
      "Epoch 51/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3882 - accuracy: 0.8518\n",
      "Epoch 52/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3854 - accuracy: 0.85212s - - ETA: 1s - loss: 0.3853  - ETA: 0s - loss: 0.3852 - accuracy: \n",
      "Epoch 53/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3847 - accuracy: 0.8526\n",
      "Epoch 54/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3862 - accuracy: 0.8528\n",
      "Epoch 55/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3843 - accuracy: 0.8529: 17s - los - ETA: 1s - loss:\n",
      "Epoch 56/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3842 - accuracy: 0.8536\n",
      "Epoch 57/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3832 - accuracy: 0.8534\n",
      "Epoch 58/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3838 - accuracy: 0.8534\n",
      "Epoch 59/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3827 - accuracy: 0.8538\n",
      "Epoch 60/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3837 - accuracy: 0.8536\n",
      "Epoch 1/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.6630 - accuracy: 0.6329\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.6063 - accuracy: 0.8082\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.5603 - accuracy: 0.8438\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.5210 - accuracy: 0.8492\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.4844 - accuracy: 0.8581\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.4502 - accuracy: 0.8686\n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4214 - accuracy: 0.8765\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.3965 - accuracy: 0.8830\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.3774 - accuracy: 0.8873s - loss: 0.3\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3610 - accuracy: 0.8919\n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.3445 - accuracy: 0.8971\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.3326 - accuracy: 0.8994\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3170 - accuracy: 0.9046\n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.3045 - accuracy: 0.9083\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.2920 - accuracy: 0.9117\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.2827 - accuracy: 0.9144\n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.2729 - accuracy: 0.9171\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.2648 - accuracy: 0.9190s - loss: 0.2654 - ac - ETA: 1s - loss:\n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.2529 - accuracy: 0.9228\n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2493 - accuracy: 0.9229TA\n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2363 - accuracy: 0.9280\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2327 - accuracy: 0.92780s - loss: 0.2325 - ac\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2281 - accuracy: 0.9294\n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2220 - accuracy: 0.9303\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.2152 - accuracy: 0.9322\n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2109 - accuracy: 0.9333\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2052 - accuracy: 0.9351\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1994 - accuracy: 0.9366\n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 0.1958 - accuracy: 0.9378\n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.1905 - accuracy: 0.9390\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 0.1846 - accuracy: 0.9417\n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 0.1832 - accuracy: 0.9410\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.1794 - accuracy: 0.9422\n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.1766 - accuracy: 0.9426s - loss: 0.1763 - \n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1733 - accuracy: 0.9439ETA: 6s - loss: 0.1735 - accuracy: 0. - ETA: 6s - loss: 0.1728 - accuracy:  - ETA: 6s\n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1692 - accuracy: 0.9452\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1685 - accuracy: 0.9446\n",
      "Epoch 38/60\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.1605 - accuracy: 0.9479\n",
      "Epoch 39/60\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.1570 - accuracy: 0.9483\n",
      "Epoch 40/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1544 - accuracy: 0.9490\n",
      "Epoch 41/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1533 - accuracy: 0.9492\n",
      "Epoch 42/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1509 - accuracy: 0.9498\n",
      "Epoch 43/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1451 - accuracy: 0.9520\n",
      "Epoch 44/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1433 - accuracy: 0.9522\n",
      "Epoch 45/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1401 - accuracy: 0.9534\n",
      "Epoch 46/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1392 - accuracy: 0.9534\n",
      "Epoch 47/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1373 - accuracy: 0.9541ETA: 13s - loss: 0.1379 - accur - ETA: 12s - loss: 0.1376 - accuracy: 0. - ETA: 12s - loss: 0.1363 - accuracy: 0. - E\n",
      "Epoch 48/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1349 - accuracy: 0.9551s - loss: 0.1352 - accuracy: 0.95\n",
      "Epoch 49/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1347 - accuracy: 0.9547\n",
      "Epoch 50/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1360 - accuracy: 0.9536s - l\n",
      "Epoch 51/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1305 - accuracy: 0.9560\n",
      "Epoch 52/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1299 - accuracy: 0.95621s - loss:\n",
      "Epoch 53/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.1298 - accuracy: 0.9554\n",
      "Epoch 54/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1292 - accuracy: 0.9562\n",
      "Epoch 55/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1279 - accuracy: 0.9565: 17s - lo - ETA: 13s - loss: 0.1266 - accuracy:  - ETA: 13s - loss: 0.1281 - accura - ETA: 4s - loss: 0.127 - - ETA: 1s - loss: 0.1279 - accuracy: 0.95 - ETA\n",
      "Epoch 56/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1260 - accuracy: 0.9568: 15s - loss: - ETA: 9s - loss: 0.1273 - accu - ETA: 9s - loss: 0 - ETA: 8s -\n",
      "Epoch 57/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1257 - accuracy: 0.95693s - loss: 0.1268 - accuracy:  - ETA: 1s - los\n",
      "Epoch 58/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1224 - accuracy: 0.9580\n",
      "Epoch 59/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1217 - accuracy: 0.9583s - loss: 0.1209 - accuracy -\n",
      "Epoch 60/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1220 - accuracy: 0.95839s - ETA: 1s - loss:\n",
      "Epoch 1/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.6630 - accuracy: 0.6459\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.6059 - accuracy: 0.8215\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.5610 - accuracy: 0.8432s - loss: 0.5613 - accuracy\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.5230 - accuracy: 0.8467\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.4893 - accuracy: 0.8531\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4578 - accuracy: 0.8617\n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4306 - accuracy: 0.8699\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.4045 - accuracy: 0.8788\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.3843 - accuracy: 0.8840\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.3662 - accuracy: 0.8887s - loss: 0.3667 - ac - ETA: 0s - loss: 0.3664 \n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.3494 - accuracy: 0.8939\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3345 - accuracy: 0.8981s - loss: 0 - ETA: 0s - loss: 0.3344 - accura\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.3209 - accuracy: 0.9022s - loss: 0.3211 - accuracy - ETA:  - ETA: 0s - loss: 0.3209 - accuracy: 0.\n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.3058 - accuracy: 0.9069\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.2978 - accuracy: 0.9080\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.2852 - accuracy: 0.9121\n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.2767 - accuracy: 0.9141\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.2690 - accuracy: 0.9160\n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.2625 - accuracy: 0.9171\n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.2516 - accuracy: 0.9206\n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.2445 - accuracy: 0.9229s - loss: 0.245 - ETA: 1s - loss: 0.2452 - ac - ETA: 1s - loss:\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 0.2367 - accuracy: 0.9251\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.2282 - accuracy: 0.9279s - loss: - ETA: 1s - loss:\n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.2266 - accuracy: 0.9274\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.2185 - accuracy: 0.9311\n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.2141 - accuracy: 0.9312s - loss: 0.2142 - accura\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.2125 - accuracy: 0.9312\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.2037 - accuracy: 0.9340s - loss: 0.2040 - accu\n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1991 - accuracy: 0.9361\n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1943 - accuracy: 0.9366s - ETA: 1s - los\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1940 - accuracy: 0.9366s - loss: 0.1940 - accuracy: 0.93 - ETA: 3s - - ETA: 0s - loss: 0.1940 - accuracy: 0.\n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1879 - accuracy: 0.9384\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.1865 - accuracy: 0.9387s - loss: 0.1862 - accu - ETA: 1s - loss: 0.1867 - accura - ETA: 0s - loss: 0.1865 - ac\n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1820 - accuracy: 0.9398\n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1776 - accuracy: 0.94147s - loss: 0.1777 - accura - ETA: 7s - loss: 0.1773 - \n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1716 - accuracy: 0.9434s - los - ETA: 0s - loss: 0.1713 - accura\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1729 - accuracy: 0.9426s - loss: 0.173\n",
      "Epoch 38/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1690 - accuracy: 0.9433\n",
      "Epoch 39/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1638 - accuracy: 0.94516s - loss: 0.1643 - accuracy -\n",
      "Epoch 40/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1598 - accuracy: 0.9465s - loss: 0.1598 - accuracy: 0.\n",
      "Epoch 41/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1568 - accuracy: 0.9472s - loss: 0.1569 - accuracy:  - ETA: 1s -\n",
      "Epoch 42/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1546 - accuracy: 0.9479\n",
      "Epoch 43/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1511 - accuracy: 0.9490 10s -  - ETA: 1s - l\n",
      "Epoch 44/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1488 - accuracy: 0.9500s - loss: 0 - ETA: 0s - loss: 0.1486 - accu\n",
      "Epoch 45/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1444 - accuracy: 0.9513s - loss: 0.1441 - ac\n",
      "Epoch 46/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.1425 - accuracy: 0.9523\n",
      "Epoch 47/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1439 - accuracy: 0.9507\n",
      "Epoch 48/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1399 - accuracy: 0.9525 16s - loss: 0.1413 - accuracy: 0.9 - ETA: 15s - loss: 0.1403 - accuracy: 0 - ETA: 15s - los\n",
      "Epoch 49/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.1415 - accuracy: 0.9514s - loss: 0.141 - ETA: 0s - loss: 0.1416 - accuracy: 0.\n",
      "Epoch 50/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1388 - accuracy: 0.9525\n",
      "Epoch 51/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1362 - accuracy: 0.9535\n",
      "Epoch 52/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1378 - accuracy: 0.9522\n",
      "Epoch 53/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1321 - accuracy: 0.9545\n",
      "Epoch 54/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1343 - accuracy: 0.95346s - loss: 0.1353 - accuracy:  - ETA: 6s - loss: 0.1354 - accuracy - ETA: 6s - loss: 0.1351  - ETA: 0s - loss: 0.1346 \n",
      "Epoch 55/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1343 - accuracy: 0.9531\n",
      "Epoch 56/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.1332 - accuracy: 0.9535s - ETA: 0s - loss: 0.1332 - accu\n",
      "Epoch 57/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1320 - accuracy: 0.9538\n",
      "Epoch 58/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1293 - accuracy: 0.9552 16s -  - ETA: 1s - loss: 0.1292 -  - ETA: 0s - loss: 0.1295 - ac\n",
      "Epoch 59/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1273 - accuracy: 0.9556s - loss: 0.1282 - accuracy:  - ETA: 2s - loss: 0.1280 - accura - ETA: 1s - loss: 0.1275 - accura - ETA: 1s - l\n",
      "Epoch 60/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1259 - accuracy: 0.9560\n",
      "Epoch 1/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.6612 - accuracy: 0.7285s - loss: 0.6692 - accura - ETA: 0s - loss: 0.6618 - accura\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.6065 - accuracy: 0.8393s - l\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.5616 - accuracy: 0.8416 - ETA: 3s - loss: 0\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.5244 - accuracy: 0.8442\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4919 - accuracy: 0.8491\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4644 - accuracy: 0.8546\n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4381 - accuracy: 0.86221s - loss: - ETA: 0s - loss: 0.4386 - ac\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4152 - accuracy: 0.8692s - loss: 0.4162 - accuracy:  - ETA: 1s -\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3951 - accuracy: 0.8755\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3771 - accuracy: 0.88060s - loss: 0.3773 - accura - ETA: 0s - loss: 0.3772 - accuracy: 0.88 - ETA: 0s - loss: 0.3771 - accuracy: 0.\n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3591 - accuracy: 0.88743s - loss: 0.3609 - accuracy - ETA: 3s -\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3452 - accuracy: 0.8907s - loss: 0.3452 - accuracy: 0.\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3290 - accuracy: 0.8961\n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3169 - accuracy: 0.8992\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3077 - accuracy: 0.9020s - loss: 0.308\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2968 - accuracy: 0.9045\n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2858 - accuracy: 0.9083\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2777 - accuracy: 0.9107TA: 1s - loss: 0\n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.2705 - accuracy: 0.9125s -\n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.2595 - accuracy: 0.9158s - loss: 0.2 - ETA\n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2528 - accuracy: 0.9180\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.2450 - accuracy: 0.9206\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.2383 - accuracy: 0.9226\n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2351 - accuracy: 0.9226\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.2262 - accuracy: 0.9262 10s - los\n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.2239 - accuracy: 0.9263\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2188 - accuracy: 0.9279s - loss: 0.2191 - accuracy:  - ETA: 2s - loss: 0.2189 - ac - ETA: 1s - los\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2115 - accuracy: 0.9308\n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.2095 - accuracy: 0.9303s - loss: 0.2097 - accuracy: \n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.2020 - accuracy: 0.9329s - loss: 0.2038 - accuracy:  - ETA: 8s\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2015 - accuracy: 0.93215s - loss: 0.203 - ETA: 4s - loss: 0 - ETA - ETA: 1s\n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1982 - accuracy: 0.9331s - loss: 0.1980 - accura\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.1957 - accuracy: 0.9335\n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1932 - accuracy: 0.9343s - loss: 0.1938 - accuracy - ETA: 1s - - ETA: 0s - loss: 0.1930 - accuracy: \n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1870 - accuracy: 0.9367\n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1836 - accuracy: 0.9373\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.1795 - accuracy: 0.9388A: \n",
      "Epoch 38/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.1771 - accuracy: 0.9395 15s - loss: 0.1610 -  - ETA: 17s - loss: 0 - ETA: 15s - loss: 0.1779 - a - ETA: 3s - loss: 0.1770 -  - ETA: 0s - loss: 0.1771 - accuracy: 0.93\n",
      "Epoch 39/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1710 - accuracy: 0.94211s\n",
      "Epoch 40/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1651 - accuracy: 0.9443\n",
      "Epoch 41/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1659 - accuracy: 0.9431s - - ETA: 2s - - ETA: 0s - loss: 0.1655 \n",
      "Epoch 42/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.1629 - accuracy: 0.9441 10s \n",
      "Epoch 43/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1576 - accuracy: 0.9466\n",
      "Epoch 44/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.1578 - accuracy: 0.94550s - loss: 0.1579 - accura\n",
      "Epoch 45/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.1555 - accuracy: 0.9464s - loss: 0\n",
      "Epoch 46/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1545 - accuracy: 0.9462\n",
      "Epoch 47/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.1542 - accuracy: 0.94623s - loss: 0.1537  - ETA: 2s - loss: - ETA: \n",
      "Epoch 48/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1492 - accuracy: 0.9481s - loss: 0.1490 - accuracy:  - ETA: 2s - loss: 0.149 - ETA: 1s - los\n",
      "Epoch 49/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1501 - accuracy: 0.9474\n",
      "Epoch 50/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1445 - accuracy: 0.9499\n",
      "Epoch 51/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1461 - accuracy: 0.9489s - loss: 0.1460 - ac\n",
      "Epoch 52/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.1444 - accuracy: 0.9493s - loss: 0.1447 - accura\n",
      "Epoch 53/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.1461 - accuracy: 0.9484\n",
      "Epoch 54/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.1438 - accuracy: 0.9490\n",
      "Epoch 55/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.1442 - accuracy: 0.9489\n",
      "Epoch 56/60\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.1415 - accuracy: 0.9497\n",
      "Epoch 57/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.1398 - accuracy: 0.9503: 15s - l - ETA: 5s - los -\n",
      "Epoch 58/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.1396 - accuracy: 0.95030s - loss: 0.1394 - accura - ETA: 0s - loss: 0.1394 - accuracy: 0.\n",
      "Epoch 59/60\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.1369 - accuracy: 0.95142s - loss: 0\n",
      "Epoch 60/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.1347 - accuracy: 0.9527\n",
      "Epoch 1/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.6718 - accuracy: 0.6142\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.6135 - accuracy: 0.7904\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.5624 - accuracy: 0.8321\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.5079 - accuracy: 0.83340s - loss: 0.5079 - accuracy: 0.83\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4643 - accuracy: 0.8334\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4505 - accuracy: 0.83331s - l - ETA: 0s - loss: 0.4506 - accuracy: \n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4472 - accuracy: 0.8333\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.4457 - accuracy: 0.8333\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.4446 - accuracy: 0.8333\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4436 - accuracy: 0.8333\n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4426 - accuracy: 0.8333\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4433 - accuracy: 0.83344s - loss: 0.4433 - accuracy: 0. - - ETA: 2s - los - ETA: 1s - los\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4420 - accuracy: 0.8333\n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4401 - accuracy: 0.8333: 10s -\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4409 - accuracy: 0.8333TA: 1s -\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4401 - accuracy: 0.8334\n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4394 - accuracy: 0.8333\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4388 - accuracy: 0.8334\n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4378 - accuracy: 0.8334ETA: \n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.4373 - accuracy: 0.83340s - loss: 0.4373 - accuracy: \n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4368 - accuracy: 0.8334\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4360 - accuracy: 0.8334s - loss: 0.436 - ETA: 1s - loss:\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4361 - accuracy: 0.8334\n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4349 - accuracy: 0.8334\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4339 - accuracy: 0.8335\n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4338 - accuracy: 0.8335\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4330 - accuracy: 0.8336\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4327 - accuracy: 0.8335s - loss: 0.4329 - accuracy\n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4333 - accuracy: 0.8336\n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4318 - accuracy: 0.8337\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4332 - accuracy: 0.8337\n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4316 - accuracy: 0.8337\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4309 - accuracy: 0.8338 - ETA: 0s - loss: 0.4306 - accu\n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.4319 - accuracy: 0.8338\n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4298 - accuracy: 0.8339\n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4283 - accuracy: 0.8340\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4294 - accuracy: 0.8339\n",
      "Epoch 38/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4276 - accuracy: 0.8341\n",
      "Epoch 39/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4269 - accuracy: 0.8343\n",
      "Epoch 40/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4265 - accuracy: 0.8345: 17s - loss: 0.4279 - - ETA: 16s - loss: 0.4265 - accur - ETA\n",
      "Epoch 41/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4255 - accuracy: 0.8344\n",
      "Epoch 42/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4238 - accuracy: 0.8351\n",
      "Epoch 43/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4237 - accuracy: 0.8350\n",
      "Epoch 44/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4226 - accuracy: 0.8352: 13s - l\n",
      "Epoch 45/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4235 - accuracy: 0.83531s - loss: 0\n",
      "Epoch 46/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4214 - accuracy: 0.83552s - loss: 0.4220 - accuracy: 0.83 - ETA: 2s - - ETA: 1s - loss: 0.4217  - ETA: 0s - loss: 0.4216 - accura\n",
      "Epoch 47/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4220 - accuracy: 0.8356TA: 6s - loss: 0.4236 - accura - ETA\n",
      "Epoch 48/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4219 - accuracy: 0.8355\n",
      "Epoch 49/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4225 - accuracy: 0.83580s - loss: 0.4225 - accuracy\n",
      "Epoch 50/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4234 - accuracy: 0.83572s - loss: 0.4231  - ETA - ETA: 0s - loss: 0.4234 - accuracy: 0.\n",
      "Epoch 51/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4190 - accuracy: 0.83574s - l - ETA: 2s - loss: 0.4193 - \n",
      "Epoch 52/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4206 - accuracy: 0.8358\n",
      "Epoch 53/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4217 - accuracy: 0.83610s - loss: 0.4218 - accuracy: \n",
      "Epoch 54/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4188 - accuracy: 0.8364\n",
      "Epoch 55/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4210 - accuracy: 0.8365\n",
      "Epoch 56/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4183 - accuracy: 0.8364\n",
      "Epoch 57/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4188 - accuracy: 0.8367\n",
      "Epoch 58/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4170 - accuracy: 0.8367\n",
      "Epoch 59/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4188 - accuracy: 0.8369s - l\n",
      "Epoch 60/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4184 - accuracy: 0.8370\n",
      "Epoch 1/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.6674 - accuracy: 0.6483s - loss: 0.6678 - accuracy\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.6060 - accuracy: 0.8197\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.5298 - accuracy: 0.8332 11s - loss: 0.5535 - accuracy: 0.8 - ETA: 10s - loss: 0.5529 - accuracy: - ETA: 10s - loss: 0.5515 - accur - E - ETA: 0s - loss: 0.531\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4691 - accuracy: 0.8333\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4519 - accuracy: 0.8333\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4487 - accuracy: 0.8333s - loss: 0.4487 - accuracy: \n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4478 - accuracy: 0.8333s\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.4481 - accuracy: 0.8333\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.4472 - accuracy: 0.8333\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4460 - accuracy: 0.83332s - loss: 0.4459 - accu -\n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4461 - accuracy: 0.8333s - - ETA: 1s - loss: 0.4460 - accuracy: 0.83 - ETA: 0s - loss: 0.4\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4452 - accuracy: 0.8333\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4437 - accuracy: 0.8333s - loss: 0.4 - ETA: 0s - loss: 0.4439 \n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4433 - accuracy: 0.8334\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4427 - accuracy: 0.8334\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4424 - accuracy: 0.8334- ETA: \n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4417 - accuracy: 0.8334\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4417 - accuracy: 0.83340s - loss: 0.4418 - \n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4401 - accuracy: 0.8334\n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4397 - accuracy: 0.8335\n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4396 - accuracy: 0.8335\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4394 - accuracy: 0.83341s - loss: 0.4395  - ETA: 1s - loss: 0\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4387 - accuracy: 0.8334s - loss: 0.4387 - accuracy: 0.\n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4379 - accuracy: 0.8335\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4369 - accuracy: 0.8335\n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4375 - accuracy: 0.8335s - loss: 0.4373 - accuracy - ETA: 0s - loss: 0.437\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4372 - accuracy: 0.8336s - loss:\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4357 - accuracy: 0.8336s - loss: 0.4358 - accura\n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4350 - accuracy: 0.8336s - loss: 0.4350 - accura\n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4361 - accuracy: 0.83371s - loss: 0.4362 - accuracy - ETA: 1s - loss: 0.4361 - accuracy: 0.83 - ETA: 0s - loss: 0.4\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.4342 - accuracy: 0.8339\n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4343 - accuracy: 0.8338\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4332 - accuracy: 0.8340\n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4321 - accuracy: 0.8341\n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4318 - accuracy: 0.8342\n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4316 - accuracy: 0.8343\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4317 - accuracy: 0.8344\n",
      "Epoch 38/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4298 - accuracy: 0.8346\n",
      "Epoch 39/60\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.4289 - accuracy: 0.8348\n",
      "Epoch 40/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4285 - accuracy: 0.8351\n",
      "Epoch 41/60\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.4274 - accuracy: 0.8353\n",
      "Epoch 42/60\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.4247 - accuracy: 0.8357\n",
      "Epoch 43/60\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.4265 - accuracy: 0.8359\n",
      "Epoch 44/60\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.4255 - accuracy: 0.8363\n",
      "Epoch 45/60\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.4258 - accuracy: 0.8360\n",
      "Epoch 46/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4260 - accuracy: 0.8360 ETA:  - ETA: 0s - loss: 0.4262 - accu\n",
      "Epoch 47/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4239 - accuracy: 0.83666s - los - ETA: 5s - l\n",
      "Epoch 48/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4259 - accuracy: 0.83620s - loss: 0.4259 - accura\n",
      "Epoch 49/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4243 - accuracy: 0.8369\n",
      "Epoch 50/60\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.4216 - accuracy: 0.8370\n",
      "Epoch 51/60\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.4213 - accuracy: 0.8374\n",
      "Epoch 52/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4221 - accuracy: 0.83752s - loss: 0.421\n",
      "Epoch 53/60\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.4210 - accuracy: 0.8376\n",
      "Epoch 54/60\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.4205 - accuracy: 0.8382\n",
      "Epoch 55/60\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4205 - accuracy: 0.83812s - loss: 0.4209 - \n",
      "Epoch 56/60\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4192 - accuracy: 0.83820s - loss: 0.419\n",
      "Epoch 57/60\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4186 - accuracy: 0.83900s - loss: 0.4188 - accuracy\n",
      "Epoch 58/60\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.4196 - accuracy: 0.8388 - ETA: 3s - l\n",
      "Epoch 59/60\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.4194 - accuracy: 0.8391\n",
      "Epoch 60/60\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.4189 - accuracy: 0.8391\n"
     ]
    }
   ],
   "source": [
    "samp_coef_list = [-1,-0.7, -0.5, -0.2, 0, 0.2, 0.5, 0.7, 1]\n",
    "for i in range (len(samp_coef_list)):\n",
    "    full_process(30,3,5,50,samp_coef_list[i],0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-winner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
